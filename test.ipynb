{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataloader\n",
    "from utils.graph import plot_attention, graph_to_adj, adj_to_graph, plot_graph\n",
    "from utils.dataset.build import generate_planar, generate_misclass \n",
    "from models import get_model, Transformer\n",
    "\n",
    "\n",
    "from transformer_lens import ActivationCache, utils, FactoredMatrix\n",
    "from transformer_lens.hook_points import HookPoint \n",
    "import circuitsvis as cv\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import wandb\n",
    "from jaxtyping import Float, Int\n",
    "import numpy as np\n",
    "\n",
    "import yaml\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Optional, Callable, Union, Sequence, List\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'trained_models/transformer_2024-09-05_13-28-07'\n",
    "\n",
    "wandb.init(\n",
    "    config=path+'.yaml',\n",
    "    mode='disabled'\n",
    ")\n",
    "\n",
    "args = wandb.config\n",
    "\n",
    "model = get_model(args)\n",
    "model.eval()\n",
    "device = model.cfg.device\n",
    "state_dict = torch.load(path+'.pt',map_location=device)\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test model on val set and random graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_dataloader('adj','data/n10_15-21_tn_vn/val.npz',1)\n",
    "n_planar = n_correct = 0\n",
    "for x,y in loader:\n",
    "    # plot_graph(adj_to_graph(x.squeeze()))\n",
    "    logits = model(x)\n",
    "    correct = logits.argmax()==y\n",
    "    n_planar += y.item()*correct\n",
    "    n_correct += correct\n",
    "\n",
    "print(f\"Val Set Accuracy: {(100*n_correct/len(loader)).item():.2f}%\")\n",
    "print(f\"{(100*n_planar/n_correct).item():.2f}% of correctly classified graphs were planar.\")\n",
    "print()\n",
    "\n",
    "for m in range(11,23):\n",
    "    n_planar = n_correct = 0\n",
    "    n_samples = 1000\n",
    "    for _ in range(n_samples):\n",
    "        g = nx.gnm_random_graph(args.n_vertices,m)\n",
    "        y = nx.is_planar(g)\n",
    "        x = torch.tensor(nx.adjacency_matrix(g).toarray(),dtype=torch.float)\n",
    "        logits = model(x)\n",
    "        correct = logits.argmax()==y\n",
    "        n_planar += y*correct\n",
    "        n_correct += correct\n",
    "\n",
    "        # print(f\"y: {y}\")\n",
    "        # print(f\"logits.argmax(): {logits.argmax()}\")\n",
    "        # print(f\"correct: {correct}\")\n",
    "        # plt.figure(figsize=(8, 6))\n",
    "        # nx.draw(g, with_labels=True, node_color='lightblue', edge_color='gray', node_size=500, font_size=10)\n",
    "        # plt.title(\"Random Graph\")\n",
    "        # plt.show()\n",
    "\n",
    "    print(f\"Accuracy on {n_samples} random graphs with {m} edges: {(100*n_correct/n_samples).item():.2f}%\")\n",
    "    print(f\"{(100*n_planar/n_correct).item():.2f}% of correctly classified graphs were planar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cache activations from example graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 19\n",
    "\n",
    "petersen_graph = graph_to_adj(nx.petersen_graph())\n",
    "cycle_graph = graph_to_adj(nx.cycle_graph(model.cfg.n_vertices))\n",
    "complete_graph = graph_to_adj(nx.complete_graph(model.cfg.n_vertices))\n",
    "empty_graph = graph_to_adj(nx.empty_graph(model.cfg.n_vertices))\n",
    "star_graph = graph_to_adj(nx.star_graph(model.cfg.n_vertices-1))\n",
    "random_graph = graph_to_adj(nx.gnm_random_graph(model.cfg.n_vertices,m))\n",
    "\n",
    "loader = get_dataloader('adj','data/n10_15-21_tn_vn/val.npz',128)\n",
    "batch,batch_labels = next(iter(loader))\n",
    "\n",
    "model.set_use_attn_result(True)\n",
    "_, petersen_cache = model.run_with_cache(petersen_graph)\n",
    "_, cycle_cache = model.run_with_cache(cycle_graph)\n",
    "_, complete_cache = model.run_with_cache(complete_graph)\n",
    "_, empty_cache = model.run_with_cache(empty_graph)\n",
    "_, star_cache = model.run_with_cache(star_graph)\n",
    "_, random_cache = model.run_with_cache(random_graph)\n",
    "_, batch_cache = model.run_with_cache(batch)\n",
    "model.set_use_attn_result(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Plot attention patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention(adj_to_graph(random_graph),random_cache[\"pattern\",1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: In Head 1.6 vertices of low degree attend stongly to vertex 2. Let's try and work out how each vertex knows whether or not it has low degree. This can easily be read off from the input but we don't know that's what the model is actually doing. \n",
    "\n",
    "My first guess as to how the attention pattern in head 1.6 comes about is this:\n",
    "- Each vertex of low degree has the concept of \"I am a vertex of low degree\" encoded in its residual stream position. \n",
    "- The query matrix for head 1.6 reads this information from the residual stream and produces queries that encode the concept \"I am looking for the special vertex position\" in low degree vertex positions.\n",
    "- The key matrix for head 1.6 produces a key that says \"I am in the special vertex position\" in position 2. I have no idea why, i guess position 2 might contain useful information that the model wants low degree vertices to have?\n",
    "\n",
    "If my guess is true, then any degree information would be passed into head 1.6 via Q-composition from components earlier in the model. Let't take a look at how earlier components contribute to the query and key in head 1.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(input: Float[Tensor,\"batch n_vertices d_model\"],model,layer):\n",
    "    return model.blocks[layer].mlp(input)\n",
    "\n",
    "mlp_0 = partial(mlp,model=model,layer=0)\n",
    "\n",
    "def decompose_qk_input(cache: ActivationCache) -> Float[Tensor, \"batch n_components n_vertices d_model\"]:\n",
    "\n",
    "    y_embed = cache[\"embed\"].unsqueeze(dim=1) # (batch 1 n_vertices d_model)\n",
    "    y_pos = cache[\"pos_embed\"].unsqueeze(dim=1) # (batch 1 n_vertices d_model)\n",
    "    y_heads = cache[\"result\", 0].transpose(1, 2) # (batch n_heads n_vertices d_model)\n",
    "    y_stack = torch.cat([y_embed, y_pos, y_heads], dim=1)\n",
    "\n",
    "    return mlp_0(y_stack) + y_stack\n",
    "\n",
    "\n",
    "def decompose_q(\n",
    "    decomposed_qk_input: Float[Tensor, \"batch n_components n_vertices d_head\"],\n",
    "    head_index: int,\n",
    "    model: Transformer,\n",
    ") -> Float[Tensor, \"batch n_components n_vertices d_head\"]:\n",
    "\n",
    "    W_Q = model.W_Q[1, head_index]\n",
    "\n",
    "    return einops.einsum(\n",
    "        decomposed_qk_input, W_Q,\n",
    "        \"batch n_components n_vertices d_model, d_model d_head -> batch n_components n_vertices d_head\"\n",
    "    )\n",
    "\n",
    "\n",
    "def decompose_k(\n",
    "    decomposed_qk_input: Float[Tensor, \"batch n_components n_vertices d_head\"],\n",
    "    head_index: int,\n",
    "    model: Transformer,\n",
    ") -> Float[Tensor, \"batch n_components n_vertices d_head\"]:\n",
    "\n",
    "    W_K = model.W_K[1, head_index]\n",
    "\n",
    "    return einops.einsum(\n",
    "        decomposed_qk_input, W_K,\n",
    "        \"batch n_components n_vertices d_model, d_model d_head -> batch n_components n_vertices d_head\"\n",
    "    )\n",
    "\n",
    "def decompose_attn_scores(\n",
    "    decomposed_q: Float[Tensor, \"batch n_components n_vertices d_head\"],\n",
    "    decomposed_k: Float[Tensor, \"batch n_components n_vertices d_head\"]\n",
    ") -> Float[Tensor, \"batch query_component key_component query_pos key_pos\"]:\n",
    "    \n",
    "    return einops.einsum(\n",
    "        decomposed_q, decomposed_k,\n",
    "        \"batch q_comp q_pos d_model, batch k_comp k_pos d_model -> batch q_comp k_comp q_pos k_pos\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_index = 6\n",
    "\n",
    "# First we get decomposed q and k input, and check they're what we expect\n",
    "decomposed_qk_input = decompose_qk_input(batch_cache)\n",
    "\n",
    "decomposed_q = decompose_q(decomposed_qk_input, head_index, model)\n",
    "decomposed_k = decompose_k(decomposed_qk_input, head_index, model)\n",
    "\n",
    "\n",
    "# Second, we plot our results\n",
    "component_labels = [\"Embed\", \"PosEmbed\"] + [f\"0.{h}\" for h in range(model.cfg.n_heads)]\n",
    "for decomposed_input, name in [(decomposed_q, \"query\"), (decomposed_k, \"key\")]:\n",
    "    px.imshow(\n",
    "        decomposed_input.pow(2).sum(-1).sqrt().mean(0).detach(),\n",
    "        labels={\"x\": \"Position\", \"y\": \"Component\"},\n",
    "        title=f\"Norms of components of {name}\",\n",
    "        y=component_labels,\n",
    "        color_continuous_scale='Blues',\n",
    "        width=1000, height=400\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we believe that the Norms of the components of the query and the key of head 1.6 are correlated with the importance of that component in the function of head1.6, then these plots support my theory that any degree information is passed into head 1.6 via Q-composition from components earlier in the model.\n",
    "Indeed if it was passed via K-composition then we would expect to see components of the key which have high norms across all positions, as low degree vertices can occur at any position.\n",
    "\n",
    "**Further Observations**: \n",
    "- We also see that when creating keys, head 1.6 pretty much only cares about the positional information coming from position 2. This suggests that the concept of \"I want to gather low degree vertices\"&mdash;that is encoded in the position 2 key&mdash;comes entirely from head 1.6 and is not passed on from an earlier component.\n",
    "- The query plot suggests that, out of the previous components, Embed, PosEmbed and head 0.2, are primarily responsible for passing on degree infomation to the vertex positions in head 1.6, with heads 0.1 and 0.3 playing a less important role.\n",
    "\n",
    "These plots are not fully convincing though, as the norm is not obviously a principled indicator of causality from earlier components to later ones. We can get a better idea of which components are causaly important for the function of head 1.6 by taking a single example graph and pairing up individual key and query components and seeing what attention scores they produce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_scores = decompose_attn_scores(decomposed_q, decomposed_k)\n",
    "decomposed_stds = einops.reduce(\n",
    "    decomposed_scores,\n",
    "    \"batch query_decomp key_decomp query_pos key_pos -> batch query_decomp key_decomp\",\n",
    "    torch.std\n",
    ")\n",
    "\n",
    "sample = 1 # Indexing a sample from `batch`\n",
    "zmax = 80 # Colorscale max\n",
    "\n",
    "px.imshow(\n",
    "    batch_cache['pattern',1][sample,6].detach(),\n",
    "    color_continuous_scale='Blues',\n",
    "    title=\"Original Sample Attention Pattern\"\n",
    ").show()\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=len(component_labels), \n",
    "    row_titles=component_labels,\n",
    "    y_title='Query Components',\n",
    "    cols=len(component_labels),\n",
    "    column_titles=component_labels,\n",
    "    x_title='Key Components'\n",
    ")\n",
    "\n",
    "for i,q_component in enumerate(component_labels):\n",
    "    for j,k_component in enumerate(component_labels):\n",
    "\n",
    "        heatmap = go.Heatmap(\n",
    "            z=decomposed_scores[sample, i, j].detach(),\n",
    "            colorscale='RdBu',\n",
    "            zmax=zmax,\n",
    "            zmin=-zmax\n",
    "        )\n",
    "        fig.add_trace(heatmap, row=i+1, col=j+1)\n",
    "        fig.update_yaxes(autorange='reversed')\n",
    "\n",
    "fig.update_layout(height=2000, width=2000)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# std dev over query and key positions, shown by component. Mean over whole batch\n",
    "px.imshow(\n",
    "    decomposed_stds.mean(0).detach(),\n",
    "    labels={\"x\": \"Key Component\", \"y\": \"Query Component\"},\n",
    "    title=\"Standard deviations of attention score contributions (by key and query component)\",\n",
    "    x=component_labels,\n",
    "    y=component_labels,\n",
    "    color_continuous_scale='Blues',\n",
    "    width=800\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots make me pretty confident that the QK circuit from head 0.2 to PosEmbed via head 1.6 is responsible for moving information from position 2 to low degree vertices. Specifically, head 0.2 Q-composes with head 1.6 and PosEmbed K-composes with head 1.6.\n",
    "\n",
    "While I find this all convincing, one problem with the above plots is that they all rely on activations from a single graph input or a small batch input into the model. It would be great if we could show this relationship between components just by looking at the model weights. We do this by studying the *composition scores* of each pair of components:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Composition Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comp_score(\n",
    "    W_A: Float[Tensor, \"in_A out_A\"],\n",
    "    W_B: Float[Tensor, \"out_A out_B\"]\n",
    ") -> float:\n",
    "\n",
    "    W_A_norm = W_A.pow(2).sum().sqrt()\n",
    "    W_B_norm = W_B.pow(2).sum().sqrt()\n",
    "    W_AB_norm = (W_A @ W_B).pow(2).sum().sqrt()\n",
    "\n",
    "    return (W_AB_norm / (W_A_norm * W_B_norm)).item()\n",
    "\n",
    "def plot_comp_scores(\n",
    "    model, \n",
    "    comp_scores, \n",
    "    component_labels=component_labels, \n",
    "    title: str = \"\", \n",
    "    baseline: Optional[Tensor] = None\n",
    ") -> go.Figure:\n",
    "    \n",
    "    px.imshow(\n",
    "        comp_scores,\n",
    "        y=component_labels,\n",
    "        x=[f\"1.{h}\" for h in range(model.cfg.n_heads)],\n",
    "        labels={\"x\": \"Layer 1\", \"y\": \"Layer 0\"},\n",
    "        title=title,\n",
    "        color_continuous_scale=\"RdBu\" if baseline is not None else \"Blues\",\n",
    "        color_continuous_midpoint=baseline if baseline is not None else None,\n",
    "        zmin=None if baseline is not None else 0.0,\n",
    "    ).show()\n",
    "\n",
    "def generate_single_random_comp_score() -> float:\n",
    "    '''\n",
    "    Generates a single composition score for random matrices\n",
    "    '''\n",
    "    W_A_left = torch.empty(model.cfg.d_model, model.cfg.d_head)\n",
    "    W_B_left = torch.empty(model.cfg.d_model, model.cfg.d_head)\n",
    "    W_A_right = torch.empty(model.cfg.d_model, model.cfg.d_head)\n",
    "    W_B_right = torch.empty(model.cfg.d_model, model.cfg.d_head)\n",
    "\n",
    "    for W in [W_A_left, W_B_left, W_A_right, W_B_right]:\n",
    "        torch.nn.init.kaiming_uniform_(W, a=np.sqrt(5))\n",
    "\n",
    "    W_A = W_A_left @ W_A_right.T\n",
    "    W_B = W_B_left @ W_B_right.T\n",
    "\n",
    "    return get_comp_score(W_A, W_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all QK and OV matrices\n",
    "W_QK = model.W_Q @ model.W_K.transpose(-2, -1)\n",
    "W_OV = model.W_V @ model.W_O\n",
    "\n",
    "# note: adding embed and pos_embed to output spaces may not be very principled (it was my idea and I don't know if anyone else does it)\n",
    "output_space = [\n",
    "    (mlp_0(model.W_E) + model.W_E).unsqueeze(dim=0),\n",
    "    (mlp_0(model.W_pos) + model.W_pos).unsqueeze(dim=0),\n",
    "    *list(mlp_0(W_OV[0]) + W_OV[0])\n",
    "]\n",
    "\n",
    "input_space = {\n",
    "    'Q': W_QK[1],\n",
    "    'K': W_QK[1].transpose(-2,-1),\n",
    "    'V': W_OV[1]\n",
    "}\n",
    "\n",
    "# Define tensors to hold the composition scores\n",
    "composition_scores = {\n",
    "    \"Q\": torch.zeros(model.cfg.n_heads+2, model.cfg.n_heads).to(device),\n",
    "    \"K\": torch.zeros(model.cfg.n_heads+2, model.cfg.n_heads).to(device),\n",
    "    \"V\": torch.zeros(model.cfg.n_heads+2, model.cfg.n_heads).to(device),\n",
    "}\n",
    "\n",
    "for i,out_sp in enumerate(output_space):\n",
    "    for j in range(model.cfg.n_heads):\n",
    "        for comp_type in \"QKV\":\n",
    "            composition_scores[comp_type][i, j] = get_comp_score(out_sp, input_space[comp_type][j])\n",
    "\n",
    "# baseline\n",
    "n_samples = 300\n",
    "comp_scores_baseline = np.zeros(n_samples)\n",
    "for i in tqdm(range(n_samples)):\n",
    "    comp_scores_baseline[i] = generate_single_random_comp_score()\n",
    "\n",
    "# px.histogram(\n",
    "#     comp_scores_baseline,\n",
    "#     nbins=50,\n",
    "#     width=800,\n",
    "#     labels={\"x\": \"Composition score\"},\n",
    "#     title=\"Random composition scores\"\n",
    "# )\n",
    "\n",
    "for comp_type in \"QKV\":\n",
    "    plot_comp_scores(\n",
    "        model,\n",
    "        composition_scores[comp_type], \n",
    "        title=f\"{comp_type} Composition Scores\",\n",
    "        baseline=comp_scores_baseline.mean()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This strongly supports my theory: it would be a pretty big coincidence if the output space of head 0.2 happend to be the only layer 0 head to have a strong overlap with the query input space of head 1.6 and head 0.2 wasn't integral to head 1.6's functionality. Similarly, we see that the output space of PosEmbed has a strong overlap with the key input space of head 1.6.\n",
    "\n",
    "If you still aren't convinced then let's take a \"corrupted\" graph with (in some sense) no low degree vertices as model input and then patch in the cached head 0.2 activations for a \"clean\" graph with some low degree vertices and see to what extent we can reproduce the \"clean\" behaviour of head 1.6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Activation Patching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_metric( \n",
    "    patched_cache: ActivationCache,\n",
    "    clean_cache: ActivationCache,\n",
    ") -> Float[Tensor, \"\"]:\n",
    "    patched_pattern = patched_cache['blocks.1.attn.hook_pattern']\n",
    "    clean_pattern = clean_cache['blocks.1.attn.hook_pattern']\n",
    "    return torch.norm(patched_pattern[0,6]-clean_pattern[0,6])\n",
    "\n",
    "def patch_head_outputs(\n",
    "    corrupted_head_outputs: Float[Tensor, \"batch n_vertices n_heads d_head\"],\n",
    "    hook: HookPoint,\n",
    "    head_ids: List[int],\n",
    "    clean_cache: ActivationCache\n",
    ") -> Float[Tensor, \"batch n_vertices n_heads d_head\"]:\n",
    "    '''\n",
    "    Patches the output of a given head (before it's added to the residual stream) at\n",
    "    every vertex position, using the value from the clean cache.\n",
    "    '''\n",
    "    corrupted_head_outputs[:, :, head_ids] = clean_cache[hook.name][:,:, head_ids]\n",
    "    \n",
    "    return corrupted_head_outputs\n",
    "\n",
    "def run_with_patched_heads(\n",
    "    model: Transformer,\n",
    "    corrupted_input: Float[Tensor, \"batch n_vertices n_vertices\"],\n",
    "    clean_cache: ActivationCache,\n",
    "    head_ids: List[int]\n",
    "):\n",
    "    hook_fn = partial(patch_head_outputs, head_ids=head_ids, clean_cache=clean_cache)\n",
    "    model.run_with_hooks(\n",
    "        corrupted_input,\n",
    "        fwd_hooks=[('blocks.0.attn.hook_z',hook_fn)]\n",
    "    )\n",
    "\n",
    "def rank_heads_by_patching_metric(\n",
    "    model: Transformer,\n",
    "    corrupted_input: Float[Tensor, \"batch n_vertices n_vertices\"],\n",
    "    clean_cache: ActivationCache,\n",
    "    patching_metric: Callable,\n",
    "    patching_names: Optional[Union[Callable[[str], bool], Sequence[str], str]] \n",
    ") -> Float[Tensor, \"batch n_vertices n_vertices\"]:\n",
    "    '''\n",
    "    Patches an increasing set of heads, each time adding the head that has the best effect\n",
    "    on the `patching_metric`. Displays heads in the order they were added along with the\n",
    "    metric score the achieved along with all previously added heads.\n",
    "\n",
    "    The `patching_metric` function should be called on the model's patched and clean caches. \n",
    "    The patched cache is created by caching activations specified by `patching_names`.\n",
    "    '''\n",
    "    model.reset_hooks()\n",
    "\n",
    "    patched_cache = model.add_caching_hooks(patching_names)\n",
    "\n",
    "    importance_ranking = []\n",
    "    metric_list = []\n",
    "\n",
    "    heads = list(range(model.cfg.n_heads))\n",
    "\n",
    "    while heads:\n",
    "\n",
    "        min_metric = 100\n",
    "        min_head = -1\n",
    "\n",
    "        for head in heads:\n",
    "            ids = importance_ranking + [head]\n",
    "            \n",
    "            run_with_patched_heads(model,corrupted_input,clean_cache,ids)\n",
    "\n",
    "            metric = patching_metric(patched_cache,clean_cache)\n",
    "            if metric < min_metric:\n",
    "                min_metric = metric\n",
    "                min_head = head\n",
    "\n",
    "        metric_list.append(min_metric)\n",
    "        importance_ranking.append(heads.pop(heads.index(min_head)))\n",
    "    \n",
    "    px.line(x=[str(i) for i in importance_ranking], y=metric_list, labels={'x': 'Head', 'y': 'Pattern Reconstruction Metric'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_heads_by_patching_metric(model,petersen_graph,random_cache,pattern_metric,'blocks.1.attn.hook_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(random_cache[\"pattern\",1][0,6],color_continuous_scale='Blues',title=\"Clean Pattern\").show()\n",
    "px.imshow(petersen_cache[\"pattern\",1][0,6],color_continuous_scale='Blues',title=\"Corrupted Pattern\",zmax=1).show()\n",
    "\n",
    "model.reset_hooks()\n",
    "patched_cache = model.add_caching_hooks('blocks.1.attn.hook_pattern')\n",
    "\n",
    "heads_to_patch = [[2],[1,2],[1,2,3],[0],[4],[5],[6],[7],[0,4,5,6,7]]\n",
    "\n",
    "for heads in heads_to_patch:\n",
    "    run_with_patched_heads(model,petersen_graph,random_cache,heads)\n",
    "\n",
    "    head_string = ' '.join(f'0.{head}' for head in heads)\n",
    "\n",
    "    px.imshow(\n",
    "        patched_cache['blocks.1.attn.hook_pattern'][0,6],\n",
    "        color_continuous_scale='Blues',\n",
    "        title=f\"Pattern with {head_string} patched\",\n",
    "        zmax=1\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **OV circuit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OV_circuit(model,layer,head):\n",
    "    W_O = model.W_O[layer, head]\n",
    "    W_V = model.W_V[layer, head]\n",
    "    W_E = model.W_E\n",
    "    W_U = model.W_U\n",
    "\n",
    "    OV_circuit = FactoredMatrix(W_V, W_O)\n",
    "    full_OV_circuit = W_E @ OV_circuit @ W_U\n",
    "    return full_OV_circuit, OV_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmax = 0.4\n",
    "\n",
    "layers = list(range(model.cfg.n_layers))\n",
    "heads = list(range(model.cfg.n_heads))\n",
    "fig = make_subplots(\n",
    "    rows=2, \n",
    "    row_titles=[str(i) for i in layers],\n",
    "    cols=8,\n",
    "    column_titles=[str(i) for i in heads]\n",
    ")\n",
    "\n",
    "for layer in layers:\n",
    "    for head_index in heads:\n",
    "        full_OV_circuit, OV_circuit = get_OV_circuit(model,layer,head_index)\n",
    "        heatmap = go.Heatmap(z=OV_circuit.AB.detach(),zmin=-zmax,zmax=zmax,colorscale='RdBu')\n",
    "        fig.add_trace(heatmap, row=layer+1, col=head_index+1)\n",
    "        fig.update_yaxes(autorange='reversed')\n",
    "\n",
    "# Update the layout for better visualization\n",
    "fig.update_layout(height=600, width=2000, showlegend=False)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    get_OV_circuit(model,0,2)[1].AB.detach(),\n",
    "    color_continuous_scale=\"RdBu\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualise neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acts(model,cache):\n",
    "    \"\"\"\n",
    "    Plots mean neuron activations for all mlp layers in cache.\n",
    "    \"\"\" \n",
    "    assert len(cache['embed'].shape) > 2, \"No batch dimension found.\"\n",
    "    for i in range(model.cfg.n_layers):\n",
    "        px.imshow(\n",
    "            cache[\"mlp_post\",i].mean(0), # mean over batch dimension\n",
    "            y=[f\"0.{h}\" for h in range(model.cfg.n_vertices)],\n",
    "            labels={\"x\": \"Neurons\", \"y\": \"Vertices\"},\n",
    "            title=f\"Layer {i} Neuron Activations\",\n",
    "            color_continuous_scale=\"Blues\"\n",
    "        ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acts(model,random_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Correlation between neuron activation and vertex degree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_act_correlation(\n",
    "        input: Float[Tensor,\"batch n_vertices n_vertices\"],\n",
    "        acts: Float[Tensor,\"batch n_vertices d_mlp\"]\n",
    "):\n",
    "    degrees = input.sum(dim=-1) # batch n_vertices\n",
    "    degrees_flattened = einops.rearrange(\n",
    "        degrees,\n",
    "        \"batch n_vertices -> 1 (batch n_vertices)\"\n",
    "    )\n",
    "\n",
    "    acts_flattened = einops.rearrange(\n",
    "        acts,\n",
    "        \"batch n_vertices d_mlp-> d_mlp (batch n_vertices)\"\n",
    "    )\n",
    "\n",
    "    degree_acts_stack = torch.cat([degrees_flattened,acts_flattened]) # (batch n_vertices) d_mlp+1\n",
    "    print(degree_acts_stack.shape)\n",
    "    correlations = torch.corrcoef(degree_acts_stack)[0,1:] # d_mlp\n",
    "\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_dataloader('adj','data/n10_15-21_tn_vn/val.npz',128)\n",
    "input, _ = next(iter(loader))\n",
    "_, cache = model.run_with_cache(input)\n",
    "degree_act_correlations = get_degree_act_correlation(input, cache['mlp_post',0])\n",
    "px.line(\n",
    "    y=degree_act_correlations.detach(),\n",
    "    labels={\"x\": \"Neuron\", \"y\": \"Correlation with degree\"},\n",
    "    title=f\"Correlation between neuron activation and degree\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logit attribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logit_diff_directions(\n",
    "    model,\n",
    "    labels: Int[Tensor,\"batch\"]\n",
    ") -> Float[Tensor,\"d_model batch\"]:\n",
    "    return model.W_U[:, labels] - model.W_U[:, ~labels]\n",
    "\n",
    "def get_logit_attribution(\n",
    "    component_results: Float[Tensor,\"... batch n_vertices d_model\"],\n",
    "    logit_diff_directions: Float[Tensor,\"d_model batch\"] \n",
    ") -> Float[Tensor,\"...\"]:\n",
    "\n",
    "    batch_size = logit_diff_directions.size(-1)\n",
    "    pooled_results: Float[Tensor,\"... batch d_model\"] = component_results.mean(dim=-2)\n",
    "    mean_logit_attribution = einops.einsum(\n",
    "        pooled_results,\n",
    "        logit_diff_directions,\n",
    "        \"... batch d_model, d_model batch -> ...\"\n",
    "    )/batch_size\n",
    "    return mean_logit_attribution\n",
    "\n",
    "def plot_logit_attribution(logit_attribution: Float[Tensor,\"n_components\"],component_captions: list):\n",
    "    px.line(\n",
    "        x=component_captions,\n",
    "        y=logit_attribution.detach(),\n",
    "        labels={\"x\": \"Component\", \"y\": \"Logit Attribution\"},\n",
    "        title=f\"Component Logit Attributions\"\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_results, component_captions = batch_cache.get_full_resid_decomposition(return_labels=True, expand_neurons=False)\n",
    "layer_results = torch.stack([v for k,v in batch_cache.items() if 'out' in k])\n",
    "layer_captions = [k for k in cache if 'out' in k]\n",
    "\n",
    "logit_diff_directions = get_logit_diff_directions(model,batch_labels)\n",
    "\n",
    "component_logit_attribution = get_logit_attribution(component_results,logit_diff_directions)\n",
    "layer_logit_attribution = get_logit_attribution(layer_results,logit_diff_directions)\n",
    "\n",
    "plot_logit_attribution(component_logit_attribution,component_captions)\n",
    "plot_logit_attribution(layer_logit_attribution,layer_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate 1_mlp_out further**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_results = einops.rearrange(\n",
    "    batch_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "neuron_logit_attribution = get_logit_attribution(neuron_results,logit_diff_directions)\n",
    "\n",
    "plot_logit_attribution(neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Make datasets of specific examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = {\n",
    "    'n': model.cfg.n_vertices,\n",
    "    'size': 1099,\n",
    "    'start': 15,\n",
    "    'end': 22\n",
    "}\n",
    "\n",
    "planar_graphs = generate_planar(**dataset_kwargs)\n",
    "\n",
    "non_planar_graphs = generate_planar(**dataset_kwargs, non_planar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_graphs, correct_labels = generate_misclass(\n",
    "    model=model,\n",
    "    start=15,\n",
    "    end=17,\n",
    "    size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adj in misclassified_graphs:\n",
    "    g = adj_to_graph(adj)\n",
    "    is_planar,cert = nx.check_planarity(g, counterexample=True)\n",
    "    print(is_planar)\n",
    "    plot_graph(cert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study average activations across sets of specific examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_use_attn_result(True)\n",
    "_, planar_cache = model.run_with_cache(planar_graphs)\n",
    "_, non_planar_cache = model.run_with_cache(non_planar_graphs)\n",
    "_, misclassified_cache = model.run_with_cache(misclassified_graphs)\n",
    "model.set_use_attn_result(False)\n",
    "\n",
    "plot_acts(model,planar_cache)\n",
    "plot_acts(model,non_planar_cache)\n",
    "plot_acts(model,misclassified_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logit attributions across sets of specific examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planar_neuron_results = einops.rearrange(\n",
    "    planar_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "non_planar_neuron_results = einops.rearrange(\n",
    "    non_planar_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "misclassified_neuron_results = einops.rearrange(\n",
    "    misclassified_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "planar_logit_diff_directions = get_logit_diff_directions(model,torch.ones(dataset_kwargs['size'],dtype=torch.int64))\n",
    "non_planar_logit_diff_directions = get_logit_diff_directions(model,torch.zeros(dataset_kwargs['size'],dtype=torch.int64))\n",
    "misclassified_logit_diff_directions = get_logit_diff_directions(model,torch.zeros(len(misclassified_graphs),dtype=torch.int64))\n",
    "\n",
    "planar_neuron_logit_attribution = get_logit_attribution(planar_neuron_results,planar_logit_diff_directions)\n",
    "non_planar_neuron_logit_attribution = get_logit_attribution(non_planar_neuron_results,non_planar_logit_diff_directions)\n",
    "misclassified_neuron_logit_attribution = get_logit_attribution(misclassified_neuron_results,misclassified_logit_diff_directions)\n",
    "\n",
    "plot_logit_attribution(planar_neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])\n",
    "plot_logit_attribution(non_planar_neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])\n",
    "plot_logit_attribution(misclassified_neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test theory with patching etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aisf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
