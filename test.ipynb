{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Graph, get_dataloader\n",
    "from utils.interp import *\n",
    "from utils.dataset.build import generate_planar, generate_misclass \n",
    "from models import get_model\n",
    "\n",
    "from transformer_lens import FactoredMatrix\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import wandb\n",
    "from jaxtyping import Float\n",
    "import numpy as np\n",
    "import rich\n",
    "from rich.table import Table\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'trained_models/transformer_2024-09-05_13-28-07'\n",
    "\n",
    "wandb.init(\n",
    "    config=path+'.yaml',\n",
    "    mode='disabled'\n",
    ")\n",
    "\n",
    "args = wandb.config\n",
    "\n",
    "model = get_model(args)\n",
    "model.eval()\n",
    "device = model.cfg.device\n",
    "state_dict = torch.load(path+'.pt',map_location=device)\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test model on val set and random graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_dataloader('adj','data/n10_15-21_tn_vn/val.npz',1)\n",
    "n_planar = n_correct = 0\n",
    "for x,y in loader:\n",
    "    # plot_graph(adj_to_graph(x.squeeze()))\n",
    "    logits = model(x)\n",
    "    correct = logits.argmax()==y\n",
    "    n_planar += y.item()*correct\n",
    "    n_correct += correct\n",
    "\n",
    "print(f\"Val Set Accuracy: {(100*n_correct/len(loader)).item():.2f}%\")\n",
    "print(f\"{(100*n_planar/n_correct).item():.2f}% of correctly classified graphs were planar.\")\n",
    "print()\n",
    "\n",
    "for m in range(22,30):\n",
    "    n_planar = n_correct = 0\n",
    "    n_samples = 1000\n",
    "    for _ in range(n_samples):\n",
    "        g = Graph(nx.gnm_random_graph(args.n_vertices,m))\n",
    "        y = nx.is_planar(g.G)\n",
    "        logits = model(g.A)\n",
    "        correct = logits.argmax()==y\n",
    "        n_planar += y*correct\n",
    "        n_correct += correct\n",
    "\n",
    "        # print(f\"y: {y}\")\n",
    "        # print(f\"logits.argmax(): {logits.argmax()}\")\n",
    "        # print(f\"correct: {correct}\")\n",
    "        # plt.figure(figsize=(8, 6))\n",
    "        # nx.draw(g, with_labels=True, node_color='lightblue', edge_color='gray', node_size=500, font_size=10)\n",
    "        # plt.title(\"Random Graph\")\n",
    "        # plt.show()\n",
    "\n",
    "    print(f\"Accuracy on {n_samples} random graphs with {m} edges: {(100*n_correct/n_samples).item():.2f}%\")\n",
    "    print(f\"{(100*n_planar/n_correct).item():.2f}% of correctly classified graphs were planar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cache activations from example graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 16\n",
    "\n",
    "random_graph = Graph(nx.gnm_random_graph(model.cfg.n_vertices,m))\n",
    "petersen_graph = Graph(nx.petersen_graph())\n",
    "cycle_graph = Graph(nx.cycle_graph(model.cfg.n_vertices))\n",
    "complete_graph = Graph(nx.complete_graph(model.cfg.n_vertices))\n",
    "empty_graph = Graph(nx.empty_graph(model.cfg.n_vertices))\n",
    "star_graph = Graph(nx.star_graph(model.cfg.n_vertices-1))\n",
    "\n",
    "loader = get_dataloader('adj','data/n10_15-21_tn_vn/val.npz',128)\n",
    "batch,batch_labels = next(iter(loader))\n",
    "\n",
    "model.set_use_attn_result(True)\n",
    "_, random_cache = model.run_with_cache(random_graph.A)\n",
    "_, petersen_cache = model.run_with_cache(petersen_graph.A)\n",
    "_, cycle_cache = model.run_with_cache(cycle_graph.A)\n",
    "_, complete_cache = model.run_with_cache(complete_graph.A)\n",
    "_, empty_cache = model.run_with_cache(empty_graph.A)\n",
    "_, star_cache = model.run_with_cache(star_graph.A)\n",
    "_, batch_cache = model.run_with_cache(batch)\n",
    "model.set_use_attn_result(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_planar = 0\n",
    "for g in batch:\n",
    "    graph = Graph(g)\n",
    "    n_planar += nx.is_planar(graph.G)\n",
    "print(f\"{100*n_planar/len(batch):.2f}% of the batch are planar graphs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. **Identifying a Circuit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 **Plot attention patterns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by looking at the attention patterns for specific inputs to the model. In the case of our model, attention patterns $A^h$ are 10 by 10 matrices that represent how each attention head $h$ moves information between the vertex positions of the input graph. For instance, if $A_{ij}^{1.3}$ is large, that means that lots of information is moved from vertex position $j$ to vertex position $i$. We say that vertex position $i$ *attends strongly* to vertex postion $j$.\n",
    "\n",
    "I took the usual [CircuitsVis](https://github.com/TransformerLensOrg/CircuitsVis) way of visualising language model attention patterns (in which you visualise which tokens an input sentence attend to each other on the tokens themselves) and applied it to graph inputs. This means you can select an attention pattern and hover over a vertex to see which other vertices it attends to. \n",
    "\n",
    "It is important to remember that transformers are designed so that the attention patterns in each attention head *depend on the input*. Indeed, if we rename all the vertices of a graph but keep all the edges the same, we still want the vertices to attend to each other in the same way and so the model must adjust its attention patterns accordingly. It is therefore important to study the attnetion patterns for a whole range of input graphs. This way you can get a much better idea of what each head could be doing.\n",
    "\n",
    "Have a go yourself at looking at the attention patterns for different input graphs. The example below is for the attention patterns in layer 0 for a randomly generated graph, but you can swap in any of the graphs that we cached during setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_graph.plot_attention(random_cache[\"pattern\",0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: In Head 1.6 vertices of low degree attend stongly to vertex position 2. Let's try and work out how the model does this.\n",
    "\n",
    "My first guess as to how this attention pattern in head 1.6 comes about is:\n",
    "- Each vertex of low degree has the concept of \"I am a vertex of low degree\" encoded in its residual stream position. \n",
    "- The query matrix for head 1.6 reads this information from the residual stream and produces queries that encode the concept \"I am looking for the special vertex position\" in low degree vertex positions.\n",
    "- The key matrix for head 1.6 produces a key that says \"I am in the special vertex position\" in position 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 **Patching**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this theory by looking at how earlier components contribute to the attention score in head 1.6.\n",
    "\n",
    "We are going to take a \"corrupted\" graph with (in some sense) no low degree vertices as model input and then \"patch over\" the paths leading from a collection of earlier components to the query and/or the key of head 1.6 using the cached head 0.2 activations for a \"clean\" graph with some low degree vertices. This will allow us to see to what extent we can reproduce the \"clean\" behaviour of head 1.6 using a subset of the components earlier in the model. We can use this to test my theory that degree information is passed into head 1.6 via the query and the positional information pinpointing vertex position 2 is passed in via the key. We should be able to go one further and actually identify which earlier components are responsible for passing this information on to head 1.6. \n",
    "\n",
    "By \"components\" I mean attention heads and the embedding. \n",
    "\n",
    "By \"path\" I mean the sequence of latent variables that lead from a component directly (without involving another component) to another component later in the model (in this case head 1.6).\n",
    "\"Patching over\" a path from component $A$ to component $B$ means effectively replacing all these latent varaibles with what they would be in the hypothetical scenario that component $A$'s output was replaced but all other components outputs stayed the same (even for components that come after $A$ in the model). By doing this we can get a better idea of the extent to which $A$ helps $B$ achieve its function. \n",
    "\n",
    "Notice that I choose not to include the mlps as components. Instead we say that mlps count as part of the direct path between other components. This is because (in the case of this specific circuit) it turns out that all the important paths between other components go through the mlp on layer 0. Insisting on studying paths that skip the mlp obscures important relationships that depend on mlp computation.  \n",
    "\n",
    "Because you can't in general simultaneously patch two different paths during the same forward pass, we implement the above as follows:\n",
    "1. Choose two subsets of the components that come before head 1.6 in the model (i.e. Embed, Layer 1 heads)\n",
    "2. Input a \"corrupted\" graph into the model\n",
    "3. Replace only the output of the components within our first chosen subset with the equivalent output obtained when the \"clean\" graph is the input.\n",
    "4. Continue the model forward pass and cache the query of head 1.6.\n",
    "5. Begin another forward pass on the same corrupted output and this time replace only the output of the components within our *second* chosen subset.\n",
    "6. Continue the forward pass until layer 1 and replace the query in head 1.6 with the cached query from the previous run.\n",
    "7. Observe the resulting attention pattern in head 1.6 and hopefully pinpoint which components are needed to reproduce the \"clean\" attention pattern and in what way they compose with head 1.6.\n",
    "\n",
    "This is a specific implementation of a broader technique known as *path patching*. In the cells below we carry out path patching with the following configuration details:\n",
    "- `q_heads_to_patch` specifies heads $h$ for which the path from $h$ to the query of head 1.6 will be patched.\n",
    "- `q_patch_embed` specifies whether or not to patch the path from the Embed to the query of head 1.6.\n",
    "- `k_heads_to_patch` specifies heads $h$ for which the path from $h$ to the key of head 1.6 will be patched.\n",
    "- `k_patch_embed` specifies whether or not to patch the path from the Embed to the key of head 1.6.\n",
    "\n",
    "Have a play aroung with this configuration below and see if you can gain some insight that could help with step 7 above.\n",
    "\n",
    "<details>\n",
    "  <summary>Two things to note</summary>\n",
    "  \n",
    "PosEmbed is the same for all inputs so patching it is pointless.\n",
    "\n",
    "The cell below runs path patching for several example configurations and, as such, the four variables described above are actually lists with the ith entry of each forming the configuration for the ith path patching example.\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_input = petersen_graph.A\n",
    "corrupted_cache = petersen_cache\n",
    "clean_input = random_graph.A\n",
    "clean_cache = random_cache\n",
    "\n",
    "layer_1_head = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components to patch:\n",
    "q_heads_to_patch = [[2,1],[3,4],[1,2,3]]\n",
    "q_patch_embed = [True,True,False]\n",
    "k_heads_to_patch = [[2,3],[2],[1,2,3]]\n",
    "k_patch_embed = [True,False,False]\n",
    " \n",
    "component_lists = [q_heads_to_patch,q_patch_embed,k_heads_to_patch,k_patch_embed]\n",
    "\n",
    "n_examples = len(q_heads_to_patch)\n",
    "\n",
    "assert all(len(lst) == n_examples for lst in component_lists)\n",
    "\n",
    "px.imshow(random_cache[\"pattern\",1][0,6],color_continuous_scale='Blues',title=\"Clean Pattern\",width=1000).show()\n",
    "px.imshow(petersen_cache[\"pattern\",1][0,6],color_continuous_scale='Blues',title=\"Corrupted Pattern\",zmax=1,width=1000).show()\n",
    "\n",
    "for i in range(n_examples):\n",
    "    pattern = get_path_patched_attn_pattern(\n",
    "        model,\n",
    "        corrupted_input,\n",
    "        corrupted_cache,\n",
    "        clean_input,\n",
    "        clean_cache, \n",
    "        q_heads_to_patch = q_heads_to_patch[i],\n",
    "        q_patch_embed = q_patch_embed[i],\n",
    "        k_heads_to_patch = k_heads_to_patch[i],\n",
    "        k_patch_embed = k_patch_embed[i],\n",
    "        layer_1_head = layer_1_head\n",
    "    )\n",
    "\n",
    "    q_embed_string = \" Embed and\" if q_patch_embed[i] else \"\"\n",
    "    k_embed_string = \" Embed and\" if k_patch_embed[i] else \"\"\n",
    "    title = f\"Pattern when the paths from{q_embed_string} heads {q_heads_to_patch[i]} to the query of head 1.{layer_1_head}<br>and the paths from{k_embed_string} heads {k_heads_to_patch[i]} to the key of head 1.{layer_1_head} are patched.\"\n",
    "\n",
    "    px.imshow(\n",
    "        pattern,\n",
    "        color_continuous_scale='Blues',\n",
    "        title=title,\n",
    "        zmax=1,\n",
    "        width=1000\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having played around with the setup above, I made the following observations:\n",
    "1. I cannot reproduce any of the clean pattern purely by patching paths into the key of head 1.6. This suggests there is little K-composition occuring. This does not in any way rule out my theory that the information pinpointing vertex position 2 enters head 1.6 via the key (but it doesn't support it either).\n",
    "2. Configurations involving patching the path from head 0.2 to the query of head 1.6 tend to be the ones that reproduce the clean pattern most closely. This suggests that head 0.2 is Q-composing with head 1.6.\n",
    "3. In configurations that involve head 0.2 but still miss some key parts of the pattern, adding in heads 0.1, 0.3 and/or Embed can help performance. This suggests more than one head is involved in the circuit responsible for the function of head 1.6. It also suggests that Embed has direct effect on head 1.6, not just via layer 0 heads.\n",
    "\n",
    "To be more confident in observations 2 and 3, we can quantify how well the pattern has been reproduced and then repeat the patching process above for all possible configurations and across a whole batch of graphs, recording how well the pattern has been reproduced each time.\n",
    "When I say \"all possible configurations\" I am actually ignoring configurations involving patching paths from layer 0 heads to the key of head 1.6. This to reduce the number of possible configurations to a manageable amount. Based on observation 1, I am confident that this does not missing a configuration that offers a notably good reconstruction of the clean attention pattern.\n",
    "\n",
    "I quantify the pattern reconstuction performance using the `patching_metric` below (scaled so that 1 represents no improvement over the corrupted input and 0 represents perfect reconstruction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patching_metric(\n",
    "    reconstructed_pattern: Float[Tensor,\"batch n_vertices n_vertices\"],\n",
    "    clean_pattern: Float[Tensor,\"batch n_vertices n_vertices\"],\n",
    "    corrupted_pattern: Float[Tensor,\"batch n_vertices n_vertices\"] # batch can be 1 in some cases but broadcasting handles this\n",
    "):\n",
    "    return (torch.linalg.matrix_norm(reconstructed_pattern-clean_pattern)/torch.linalg.matrix_norm(clean_pattern-corrupted_pattern)).mean().item()\n",
    "\n",
    "def get_component_string(results_key):\n",
    "    \"\"\"Given key from results dict, return dict expressing which components that key corresponds to.\"\"\"\n",
    "    q_components = 'Embed '*results_key[0][0] + ' '.join(f'0.{head}' for head in results_key[0][1:])\n",
    "    k_components = 'Embed' if results_key[1][0] else ''\n",
    "    return q_components, k_components\n",
    "\n",
    "def get_n_components_patched(results_key):\n",
    "    \"\"\"Given key from results dict, find total number of components that have been patched\"\"\"\n",
    "    return sum([\n",
    "        results_key[0][0],\n",
    "        results_key[1][0],\n",
    "        len(results_key[0][1:]),\n",
    "        len(results_key[1][1:])\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "results = get_path_patching_metric_results(\n",
    "    model,\n",
    "    corrupted_input,\n",
    "    corrupted_cache,\n",
    "    batch,\n",
    "    batch_cache,\n",
    "    patching_metric,\n",
    "    layer_1_head\n",
    ")\n",
    "   \n",
    "table = Table('Number of components patched','Best Score Achieved','Q Components Patched','K Components Patched',title='Best paths to patch for each number of components patched:')\n",
    "one_component_table = Table(\"Q component\", \"K Component\",\"Pattern Reconstruction Score\", title='Results from patching one component')\n",
    "\n",
    "for n_components_patched in range(1,model.cfg.n_heads+2):\n",
    "    filtered_results = {k:v for k,v in results.items() if get_n_components_patched(k)==n_components_patched}\n",
    "    if n_components_patched==1:\n",
    "        for k,v in filtered_results.items():\n",
    "            q_component, k_component = get_component_string(k)\n",
    "            one_component_table.add_row(q_component, k_component,f\"{v:.2f}\")\n",
    "    best_combination = min(filtered_results, key=filtered_results.get)\n",
    "    best_q_components, best_k_components = get_component_string(best_combination)\n",
    "    best_metric_score = filtered_results[best_combination]\n",
    "    table.add_row(str(n_components_patched),f\"{best_metric_score:.2f}\",best_q_components,best_k_components)\n",
    "\n",
    "rich.print(one_component_table)\n",
    "rich.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above make me pretty confident that head 0.2 Q-composing with head 1.6 is the main interaction driving the circuit behind head 1.6's function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 **Head 0.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's follow this trail back through the model by looking more closely at head 0.2.\n",
    " \n",
    "**Observation**: Vertices of high degree attend more to vertices 3 and 6, whereas vertices of low degree seem to attend evenly to all vertices.\n",
    "Although this pattern has far more evenly distributed&mdash;and therefore smaller&mdash;probabilities, it's functionality seems pretty similar to head 1.6, except with \"low degree\" swapped with \"high degree\" and position 2 swapped with positions 3 and 6.\n",
    "\n",
    "Let's test this theory using similar techniques. As before, we decompose the input to the head into components. Because this is the layer 0 we only have two input components: Embed and PosEmbed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_qk_input_layer_0 = decompose_qk_input(model, batch_cache, layer=0)\n",
    "decomposed_q_layer_0 = decompose_q(model,decomposed_qk_input_layer_0,head_index=2,layer=0)\n",
    "decomposed_k_layer_0 = decompose_k(model,decomposed_qk_input_layer_0,head_index=2,layer=0)\n",
    "\n",
    "component_labels_layer_0 = [\"Embed\", \"PosEmbed\"]\n",
    "for decomposed_input, name in [(decomposed_q_layer_0, \"query\"), (decomposed_k_layer_0, \"key\")]:\n",
    "    px.imshow(\n",
    "        decomposed_input.pow(2).sum(-1).sqrt().mean(0).detach(),\n",
    "        labels={\"x\": \"Position\", \"y\": \"Component\"},\n",
    "        title=f\"Norms of components of {name}\",\n",
    "        y=component_labels_layer_0,\n",
    "        color_continuous_scale='Blues',\n",
    "        width=1000, height=400,\n",
    "        zmin=0\n",
    "    ).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots are very similar to the ones we got for head 1.6, supporting our theory. Indeed, head 0.2 seems like it is only interested in moving information from positions 3 and 6 to vertices based purely on their embedding (and not their position).\n",
    "To be more certain we will plot the decomposed attention scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_scores_layer_0 = decompose_attn_scores(decomposed_q_layer_0, decomposed_k_layer_0)\n",
    "\n",
    "plot_decomposed_attn_scores(\n",
    "    decomposed_scores=decomposed_scores_layer_0,\n",
    "    cache=batch_cache,\n",
    "    component_labels=component_labels_layer_0,\n",
    "    layer=0,\n",
    "    head_idx=2,\n",
    "    batch_sample_idx=100,\n",
    "    zmax=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. **Zooming in**: following the circuit step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a broad overview of which components are composing to form the circuit responsible for head 1.6's function, it is time to attempt to follow this circuit through the network from input to head 1.6 in more detail.\n",
    "\n",
    "Hopefully by doing this we can answer questions like:\n",
    "- How exactly does $W_Q^{0.2}$ give the query vectors a concept of degree based on $AW_E$?\n",
    "- What does the mlp layer do to the information moving between heads 0.2 and 1.6?\n",
    "\n",
    "We begin by trying to answer the first of these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 **Input -> Head 0.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the query vectors are given by:\n",
    "\n",
    "$q = AW_EW_Q^{0.2}+ W_{pos}W_Q^{0.2}$,\n",
    "\n",
    "and that multiplying by $A$ is just summing the rows of $W_EW_Q^{0.2}$ corresponding to the vertices adjacent to each vertex. \n",
    "\n",
    "This means that studying the rows of $W_EW_Q^{0.2}$ and $W_{pos}W_Q^{0.2}$ will help us decompose what $W_Q^{0.2}$ does into smaller parts instead of looking at what it does to the entire residual stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0\n",
    "head = 2\n",
    "\n",
    "W_E = model.W_E.detach()\n",
    "W_pos = model.W_pos.detach()\n",
    "W_Q = model.W_Q[layer,head].detach()\n",
    "W_K = model.W_K[layer,head].detach()\n",
    "W_V = model.W_V[layer,head].detach()\n",
    "resid = random_cache['resid_pre',0][0]\n",
    "z = random_cache['z',layer][0,:,head]\n",
    "result = random_cache['result',layer][0,:,head]\n",
    "\n",
    "random_graph.plot()\n",
    "px.imshow(W_E,color_continuous_scale='RdBu',title='W_E',width=1500).show()\n",
    "px.imshow(W_pos,color_continuous_scale='RdBu',title='W_pos',width=1500).show()\n",
    "px.imshow(W_Q,color_continuous_scale='RdBu',title='W_Q',width=1500).show()\n",
    "px.imshow(W_E@W_Q,color_continuous_scale='RdBu',title='W_E @ W_Q',width=1500,zmax=0.5,zmin=-0.5).show()\n",
    "px.imshow(W_pos@W_Q,color_continuous_scale='RdBu',title='W_pos @ W_Q',width=1500,zmax=0.5,zmin=-0.5).show()\n",
    "px.imshow(resid@W_Q,color_continuous_scale='RdBu',title='q (= resid @ W_Q)',width=1500).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots we can observe that, given a vertex in position $i$ with degree $d_i$, $W_Q^{0.2}$ maps the embedding of all $d_i$ adjacent vertices (found in the rows of $W_E$) to pretty much the same vector $\\mathbf{v}$ (represented by the verticle stripes in the plot of $W_EW_Q^{0.2}$ above). It also maps the positional embedding of $i$ (found in the rows of $W_{pos}$) to $-2\\mathbf{v}$. As described earlier, multiplying by $A$ sums the results in the rows of $W_EW_Q^{0.2}$ meaning that row $i$ of $AW_EW_Q^{0.2}$ contains the vector $d_i\\mathbf{v}$. By then summing the results with $W_{pos}W_Q^{0.2}$ we are subtracting $2\\mathbf{v}$ meaning the query of head 0.2 has the information $d_i-2$ stored in each vertex position $i$. \n",
    "\n",
    "By identifying this direction in the latent space of head 0.2's QK circuit corresponding to the concept of degree, we can read off the degree of each vertex directly from the query $q$ plotted above.  \n",
    "\n",
    "Given this insight, we now expect the key vectors in positions 3 and 6 of head 0.2 to also point in the direction $\\mathbf{v}$, therefore causing vertices with higher degree to attend more strongly to those positions. This means that the $W_{pos}W_K^{0.2}$ should make up the majority of the key $k$ (in line with the earlier composition analysis). Sure enough, when we plot $W_EW_K^{0.2}$ and $W_{pos}W_K^{0.2}$, our expectations are met: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(W_K,color_continuous_scale='RdBu',title='W_K',width=1500).show()\n",
    "px.imshow(W_E@W_K,color_continuous_scale='RdBu',title='W_E @ W_K',width=1500,color_continuous_midpoint=0,zmax=1.25,zmin=-1.25).show()\n",
    "px.imshow(W_pos@W_K,color_continuous_scale='RdBu',title='W_pos @ W_K',width=1500,color_continuous_midpoint=0,zmax=1.25).show()\n",
    "px.imshow(resid@W_K,color_continuous_scale='RdBu',title='k (= resid @ W_K)',width=1500).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 **Head 0.2 -> Head 1.6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having reverse engineered the QK circuit of head 0.2, we now look at the OV circuit. $W_V^{0.2}$ essentially appears to be doing that same thing as $W_K^{0.2}$, except with a different direction corresponding to degree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(W_V,color_continuous_scale='RdBu',title='W_V',color_continuous_midpoint=0).show()\n",
    "px.imshow(W_E@W_V,color_continuous_scale='RdBu',title='W_E @ W_V',color_continuous_midpoint=0).show()\n",
    "px.imshow(W_pos@W_V,color_continuous_scale='RdBu',title='W_pos @ W_V',color_continuous_midpoint=0).show()\n",
    "px.imshow(resid@W_V,color_continuous_scale='RdBu',title='v (= resid @ W_V)',color_continuous_midpoint=0).show()\n",
    "px.imshow(resid@W_V,color_continuous_scale='RdBu',title='v (= resid @ W_V)',color_continuous_midpoint=0).show()\n",
    "px.imshow(z,color_continuous_scale='RdBu',title='z (attention pattern applied to v)',color_continuous_midpoint=0).show()\n",
    "px.imshow(result,color_continuous_scale='RdBu',title='result (OV circuit output)',color_continuous_midpoint=0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots we can see how the value has the attention pattern applied to it (see z plot) and then is written to the residual stream (see result plot). In every plot we can see the patterns caused by every row encoding degree in the same direction in the corresponding latent space. We now have a good understanding of how head 0.2 writes degree information to the residual stream for head 1.6 to read and use for its task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between heads 0.2 and 1.6 we have an mlp layer, which seems to shift the direction that the degree information from head 0.2 points in the residual stream, but definitely keeps it visible to the naked eye. When we look at $W_Q^{1.6}$ we see that it seems to be reading from a similar direction (e.g. look at column 68 of the residual stream and row 68 of $W_Q^{1.6}$). Of course, we already expect this as we know that heads 0.2 and 1.6 have high Q-composition scores, but it is still nice to see a concrete example of this overlap. We also observe that $W_Q^{1.6}$ exctracts the degree information to give a query, $q$, exhibiting a simlar structure to the query from head 0.2 (except with a different latent direction for degree). The realtive sizes of the query vectors in each row of $q$ are slightly less correlated with degree than they were in head 0.2, but there is still more than enough information in these vectors to identify vertices of low degree.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mlp = (mlp_0(result)+result).detach()\n",
    "W_Q_1_6 = model.W_Q[1,6].detach()\n",
    "\n",
    "px.imshow(post_mlp,color_continuous_scale='RdBu',title='Component of post mlp 0 residual stream orignating from head 0.2').show()\n",
    "px.imshow(W_Q_1_6,color_continuous_scale='RdBu',title='W_Q').show()\n",
    "px.imshow(post_mlp@W_Q_1_6,color_continuous_scale='RdBu',title='component @ W_Q').show()\n",
    "px.imshow(random_cache['resid_pre',1][0]@W_Q_1_6,color_continuous_scale='RdBu',title='q (= full residual stream @ W_Q)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, I think we have done enough to say that we have reverse engineered the circuit behind the function of head 1.6, we even followed the input step by step through each layer and identified the directions in each latent space that corresponded to degree. There are of course small contributions to the input to head 1.6 that come from heads other than 0.2 but&mdash;as we saw in our activation patching results&mdash;I don't think they are contributing anything vitally improtant for the behviour of head 1.6 that head 0.2 isn't providing by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious next question is: \"what does any of this have to do with the planarity of a graph?\". I am not sure at all. My best guess so far is that the model could be leveraging the fact that *vertices of degree less than 3 are not relevant to planarity*. Indeed for vertices of degree 0 or 1, removing them from a graph is never going to change a graph's planarity. For vertices of degree 2, replacing them with a single edge between their adjacent vertices is never going to change a graph’s planarity. Perhaps the purpose of head 1.6 is to help the model ignore this redundant information when making its decision? If true, it could help explain the significance of $W_{pos}W_Q^{0.2}$ representing “-2 in the degree direction”: it could be creating a “cutoff” below which all vertices should be in some sense ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 **Decompose input**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this theory by looking at how earlier components contribute to the query and key in head 1.6.\n",
    "\n",
    "To do this we take the input into head 1.6 (i.e. the residual stream post layer 0, $x_1$) and think of it as a sum of the outputs of all the previous components 10 components $y_i$ (i.e. the 2 embeddings and 8 layer 0 heads) which is then fed through the mlp on layer 0 $f_0$:\n",
    "$$\n",
    "x_1 = f_0\\left(\\sum_{i = 0}^9 y_i\\right) + \\sum_{i = 0}^9 y_i = f_0\\left(gW_E + W_{pos} + \\sum_{h}A^h x_0 W_{OV}^h\\right) + gW_E + W_{pos} + \\sum_{h}A^h x_0 W_{OV}^h\n",
    "$$\n",
    "Decomposing $x_1$ into each of its terms allows us to study the impact each component has on each position in the query $q$ and key $k$ of head 1.6:\n",
    "$$\n",
    "q = \\left(\\sum_{i = 0}^9 y_i\\right)W_Q^{1.6} = \\sum_{i = 0}^9 y_iW_Q^{1.6} = gW_EW_Q^{1.6} + W_{pos}W_Q^{1.6} + \\sum_{h}A^h x_0 W_{OV}^hW_Q^{1.6}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_index = 6\n",
    "\n",
    "decomposed_qk_input = decompose_qk_input(model,batch_cache)\n",
    "\n",
    "actual_resid = batch_cache['resid_post',0][0]\n",
    "naive_resid = decomposed_qk_input.sum(1)[0].detach()\n",
    "\n",
    "px.imshow(actual_resid,color_continuous_scale='RdBu',zmax=3.5,zmin=-3.5).show()\n",
    "px.imshow(naive_resid,color_continuous_scale='RdBu',zmax=4.5,zmin=-4.5).show()\n",
    "px.imshow(actual_resid-naive_resid,color_continuous_scale='RdBu',zmax=4.5,zmin=-4.5).show()\n",
    "px.imshow(model.W_Q[1,6].detach(),color_continuous_scale='RdBu').show()\n",
    "\n",
    "decomposed_q = decompose_q(model, decomposed_qk_input, head_index)\n",
    "decomposed_k = decompose_k(model, decomposed_qk_input, head_index)\n",
    "\n",
    "component_labels = [\"Embed\", \"PosEmbed\"] + [f\"0.{h}\" for h in range(model.cfg.n_heads)]\n",
    "for decomposed_input, name in [(decomposed_q, \"query\"), (decomposed_k, \"key\")]:\n",
    "    px.imshow(\n",
    "        decomposed_input.pow(2).sum(-1).sqrt().mean(0).detach(),\n",
    "        labels={\"x\": \"Position\", \"y\": \"Component\"},\n",
    "        title=f\"Norms of components of {name}\",\n",
    "        y=component_labels,\n",
    "        color_continuous_scale='Blues',\n",
    "        width=1000, height=400\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we believe that the Norms of the components of the query and the key of head 1.6 are correlated with the importance of that component in the function of head1.6, then these plots support my theory that any degree information is passed into head 1.6 via Q-composition from components earlier in the model.\n",
    "Indeed if it was passed via K-composition then we would expect to see components of the key which have high norms across all positions, as low degree vertices can occur at any position.\n",
    "\n",
    "**Further Observations**: \n",
    "- We also see that when creating keys, head 1.6 pretty much only cares about the positional information coming from position 2. This suggests that the concept of \"I want to gather low degree vertices\"&mdash;that is encoded in the position 2 key&mdash;comes entirely from head 1.6 and is not passed on from an earlier component.\n",
    "- The query plot suggests that, out of the previous components, Embed, PosEmbed and head 0.2, are primarily responsible for passing on degree infomation to the vertex positions in head 1.6, with heads 0.1 and 0.3 playing a less important role.\n",
    "\n",
    "These plots are not fully convincing though, as the norm is not obviously a principled indicator of causality from earlier components to later ones. We can get a better idea of which components are causaly important for the function of head 1.6 by taking a single example graph and pairing up individual key and query components and seeing what attention scores they produce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_scores = decompose_attn_scores(decomposed_q, decomposed_k)\n",
    "\n",
    "plot_decomposed_attn_scores(\n",
    "    decomposed_scores=decomposed_scores,\n",
    "    cache=batch_cache,\n",
    "    component_labels=component_labels,\n",
    "    head_idx=6,\n",
    "    batch_sample_idx=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This strongly supports my theory: it would be a pretty big coincidence if the output space of head 0.2 happend to be the only layer 0 head to have a strong overlap with the query input space of head 1.6 and head 0.2 wasn't integral to head 1.6's functionality. Similarly, we see that the output space of PosEmbed has a strong overlap with the key input space of head 1.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 **Composition scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all QK and OV matrices\n",
    "W_QK = model.W_Q @ model.W_K.transpose(-2, -1)\n",
    "W_OV = model.W_V @ model.W_O\n",
    "\n",
    "mlp_0 = model.blocks[0].mlp\n",
    "\n",
    "# note: adding embed and pos_embed to output spaces may not be very principled (it was my idea and I don't know if anyone else does it)\n",
    "output_space = [\n",
    "    (mlp_0(model.W_E) + model.W_E).unsqueeze(dim=0),\n",
    "    (mlp_0(model.W_pos) + model.W_pos).unsqueeze(dim=0),\n",
    "    *list(mlp_0(W_OV[0]) + W_OV[0])\n",
    "]\n",
    "\n",
    "input_space = {\n",
    "    'Q': W_QK[1],\n",
    "    'K': W_QK[1].transpose(-2,-1),\n",
    "    'V': W_OV[1]\n",
    "}\n",
    "\n",
    "# Define tensors to hold the composition scores\n",
    "composition_scores = {\n",
    "    \"Q\": torch.zeros(model.cfg.n_heads+2, model.cfg.n_heads).to(device),\n",
    "    \"K\": torch.zeros(model.cfg.n_heads+2, model.cfg.n_heads).to(device),\n",
    "    \"V\": torch.zeros(model.cfg.n_heads+2, model.cfg.n_heads).to(device),\n",
    "}\n",
    "\n",
    "for i,out_sp in enumerate(output_space):\n",
    "    for j in range(model.cfg.n_heads):\n",
    "        for comp_type in \"QKV\":\n",
    "            composition_scores[comp_type][i, j] = get_comp_score(out_sp, input_space[comp_type][j])\n",
    "\n",
    "# baseline\n",
    "n_samples = 300\n",
    "comp_scores_baseline = np.zeros(n_samples)\n",
    "for i in tqdm(range(n_samples)):\n",
    "    comp_scores_baseline[i] = generate_single_random_comp_score(model)\n",
    "\n",
    "# px.histogram(\n",
    "#     comp_scores_baseline,\n",
    "#     nbins=50,\n",
    "#     width=800,\n",
    "#     labels={\"x\": \"Composition score\"},\n",
    "#     title=\"Random composition scores\"\n",
    "# )\n",
    "\n",
    "for comp_type in \"QKV\":\n",
    "    plot_comp_scores(\n",
    "        model,\n",
    "        composition_scores[comp_type], \n",
    "        title=f\"{comp_type} Composition Scores\",\n",
    "        component_labels=component_labels,\n",
    "        baseline=comp_scores_baseline.mean()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OV circuit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OV_circuit(model,layer,head):\n",
    "    W_O = model.W_O[layer, head]\n",
    "    W_V = model.W_V[layer, head]\n",
    "    W_E = model.W_E\n",
    "    W_U = model.W_U\n",
    "\n",
    "    OV_circuit = FactoredMatrix(W_V, W_O)\n",
    "    full_OV_circuit = W_E @ OV_circuit @ W_U\n",
    "    return full_OV_circuit, OV_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmax = 0.4\n",
    "\n",
    "layers = list(range(model.cfg.n_layers))\n",
    "heads = list(range(model.cfg.n_heads))\n",
    "fig = make_subplots(\n",
    "    rows=2, \n",
    "    row_titles=[str(i) for i in layers],\n",
    "    cols=8,\n",
    "    column_titles=[str(i) for i in heads]\n",
    ")\n",
    "\n",
    "for layer in layers:\n",
    "    for head_index in heads:\n",
    "        full_OV_circuit, OV_circuit = get_OV_circuit(model,layer,head_index)\n",
    "        heatmap = go.Heatmap(z=OV_circuit.AB.detach(),zmin=-zmax,zmax=zmax,colorscale='RdBu')\n",
    "        fig.add_trace(heatmap, row=layer+1, col=head_index+1)\n",
    "        fig.update_yaxes(autorange='reversed')\n",
    "\n",
    "# Update the layout for better visualization\n",
    "fig.update_layout(height=600, width=2000, showlegend=False)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    get_OV_circuit(model,0,2)[1].AB.detach(),\n",
    "    color_continuous_scale=\"RdBu\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualise neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acts(model,cache):\n",
    "    \"\"\"\n",
    "    Plots mean neuron activations for all mlp layers in cache.\n",
    "    \"\"\" \n",
    "    assert len(cache['embed'].shape) > 2, \"No batch dimension found.\"\n",
    "    for i in range(model.cfg.n_layers):\n",
    "        px.imshow(\n",
    "            cache[\"mlp_post\",i].mean(0), # mean over batch dimension\n",
    "            y=[f\"0.{h}\" for h in range(model.cfg.n_vertices)],\n",
    "            labels={\"x\": \"Neurons\", \"y\": \"Vertices\"},\n",
    "            title=f\"Layer {i} Neuron Activations\",\n",
    "            color_continuous_scale=\"Blues\"\n",
    "        ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acts(model,batch_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Correlation between neuron activation and vertex degree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_act_correlation(\n",
    "    input: Float[Tensor,\"batch n_vertices n_vertices\"],\n",
    "    acts: Float[Tensor,\"batch n_vertices d_mlp\"]\n",
    "):\n",
    "    degrees = input.sum(dim=-1) # batch n_vertices\n",
    "    degrees_flattened = einops.rearrange(\n",
    "        degrees,\n",
    "        \"batch n_vertices -> 1 (batch n_vertices)\"\n",
    "    )\n",
    "\n",
    "    acts_flattened = einops.rearrange(\n",
    "        acts,\n",
    "        \"batch n_vertices d_mlp-> d_mlp (batch n_vertices)\"\n",
    "    )\n",
    "\n",
    "    degree_acts_stack = torch.cat([degrees_flattened,acts_flattened]) # (batch n_vertices) d_mlp+1\n",
    "    print(degree_acts_stack.shape)\n",
    "    correlations = torch.corrcoef(degree_acts_stack)[0,1:] # d_mlp\n",
    "\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_dataloader('adj','data/n10_15-21_tn_vn/val.npz',128)\n",
    "input, _ = next(iter(loader))\n",
    "_, cache = model.run_with_cache(input)\n",
    "degree_act_correlations = get_degree_act_correlation(input, cache['mlp_post',1])\n",
    "px.line(\n",
    "    y=degree_act_correlations.detach(),\n",
    "    labels={\"x\": \"Neuron\", \"y\": \"Correlation with degree\"},\n",
    "    title=f\"Correlation between neuron activation and degree\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logit attribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_results, component_captions = batch_cache.get_full_resid_decomposition(return_labels=True, expand_neurons=False)\n",
    "layer_results = torch.stack([v for k,v in batch_cache.items() if 'out' in k])\n",
    "layer_captions = [k for k in cache if 'out' in k]\n",
    "\n",
    "logit_diff_directions = get_logit_diff_directions(model,batch_labels)\n",
    "\n",
    "component_logit_attribution = get_logit_attribution(component_results,logit_diff_directions)\n",
    "layer_logit_attribution = get_logit_attribution(layer_results,logit_diff_directions)\n",
    "\n",
    "plot_logit_attribution(component_logit_attribution,component_captions)\n",
    "plot_logit_attribution(layer_logit_attribution,layer_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate 1_mlp_out further**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_results = einops.rearrange(\n",
    "    batch_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "neuron_logit_attribution = get_logit_attribution(neuron_results,logit_diff_directions)\n",
    "\n",
    "plot_logit_attribution(neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Make datasets of specific examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = {\n",
    "    'n': model.cfg.n_vertices,\n",
    "    'size': 1099,\n",
    "    'start': 15,\n",
    "    'end': 22\n",
    "}\n",
    "\n",
    "planar_graphs = generate_planar(**dataset_kwargs)\n",
    "\n",
    "non_planar_graphs = generate_planar(**dataset_kwargs, non_planar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_graphs, correct_labels = generate_misclass(\n",
    "    model=model,\n",
    "    start=15,\n",
    "    end=17,\n",
    "    size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adj in misclassified_graphs:\n",
    "    g = Graph(adj)\n",
    "    is_planar,cert = nx.check_planarity(g.G, counterexample=True)\n",
    "    print(is_planar)\n",
    "    Graph(cert).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study average activations across sets of specific examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_use_attn_result(True)\n",
    "_, planar_cache = model.run_with_cache(planar_graphs)\n",
    "_, non_planar_cache = model.run_with_cache(non_planar_graphs)\n",
    "_, misclassified_cache = model.run_with_cache(misclassified_graphs)\n",
    "model.set_use_attn_result(False)\n",
    "\n",
    "plot_acts(model,planar_cache)\n",
    "plot_acts(model,non_planar_cache)\n",
    "plot_acts(model,misclassified_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logit attributions across sets of specific examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planar_neuron_results = einops.rearrange(\n",
    "    planar_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "non_planar_neuron_results = einops.rearrange(\n",
    "    non_planar_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "misclassified_neuron_results = einops.rearrange(\n",
    "    misclassified_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "planar_logit_diff_directions = get_logit_diff_directions(model,torch.ones(dataset_kwargs['size'],dtype=torch.int64))\n",
    "non_planar_logit_diff_directions = get_logit_diff_directions(model,torch.zeros(dataset_kwargs['size'],dtype=torch.int64))\n",
    "misclassified_logit_diff_directions = get_logit_diff_directions(model,torch.zeros(len(misclassified_graphs),dtype=torch.int64))\n",
    "\n",
    "planar_neuron_logit_attribution = get_logit_attribution(planar_neuron_results,planar_logit_diff_directions)\n",
    "non_planar_neuron_logit_attribution = get_logit_attribution(non_planar_neuron_results,non_planar_logit_diff_directions)\n",
    "misclassified_neuron_logit_attribution = get_logit_attribution(misclassified_neuron_results,misclassified_logit_diff_directions)\n",
    "\n",
    "plot_logit_attribution(planar_neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])\n",
    "plot_logit_attribution(non_planar_neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])\n",
    "plot_logit_attribution(misclassified_neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aisf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
