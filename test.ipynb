{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Graph, get_dataloader\n",
    "from utils.interp import *\n",
    "from utils.dataset.build import generate_planar, generate_misclass \n",
    "from models import get_model\n",
    "\n",
    "from transformer_lens import FactoredMatrix\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import wandb\n",
    "from jaxtyping import Float\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'trained_models/transformer_2024-09-05_13-28-07'\n",
    "\n",
    "wandb.init(\n",
    "    config=path+'.yaml',\n",
    "    mode='disabled'\n",
    ")\n",
    "\n",
    "args = wandb.config\n",
    "\n",
    "model = get_model(args)\n",
    "model.eval()\n",
    "device = model.cfg.device\n",
    "state_dict = torch.load(path+'.pt',map_location=device)\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test model on val set and random graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_dataloader('adj','data/n10_15-21_tn_vn/val.npz',1)\n",
    "n_planar = n_correct = 0\n",
    "for x,y in loader:\n",
    "    # plot_graph(adj_to_graph(x.squeeze()))\n",
    "    logits = model(x)\n",
    "    correct = logits.argmax()==y\n",
    "    n_planar += y.item()*correct\n",
    "    n_correct += correct\n",
    "\n",
    "print(f\"Val Set Accuracy: {(100*n_correct/len(loader)).item():.2f}%\")\n",
    "print(f\"{(100*n_planar/n_correct).item():.2f}% of correctly classified graphs were planar.\")\n",
    "print()\n",
    "\n",
    "for m in range(11,23):\n",
    "    n_planar = n_correct = 0\n",
    "    n_samples = 1000\n",
    "    for _ in range(n_samples):\n",
    "        g = Graph(nx.gnm_random_graph(args.n_vertices,m))\n",
    "        y = nx.is_planar(g.G)\n",
    "        logits = model(g.A)\n",
    "        correct = logits.argmax()==y\n",
    "        n_planar += y*correct\n",
    "        n_correct += correct\n",
    "\n",
    "        # print(f\"y: {y}\")\n",
    "        # print(f\"logits.argmax(): {logits.argmax()}\")\n",
    "        # print(f\"correct: {correct}\")\n",
    "        # plt.figure(figsize=(8, 6))\n",
    "        # nx.draw(g, with_labels=True, node_color='lightblue', edge_color='gray', node_size=500, font_size=10)\n",
    "        # plt.title(\"Random Graph\")\n",
    "        # plt.show()\n",
    "\n",
    "    print(f\"Accuracy on {n_samples} random graphs with {m} edges: {(100*n_correct/n_samples).item():.2f}%\")\n",
    "    print(f\"{(100*n_planar/n_correct).item():.2f}% of correctly classified graphs were planar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cache activations from example graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 16\n",
    "\n",
    "petersen_graph = Graph(nx.petersen_graph())\n",
    "cycle_graph = Graph(nx.cycle_graph(model.cfg.n_vertices))\n",
    "complete_graph = Graph(nx.complete_graph(model.cfg.n_vertices))\n",
    "empty_graph = Graph(nx.empty_graph(model.cfg.n_vertices))\n",
    "star_graph = Graph(nx.star_graph(model.cfg.n_vertices-1))\n",
    "random_graph = Graph(nx.gnm_random_graph(model.cfg.n_vertices,m))\n",
    "\n",
    "loader = get_dataloader('adj','data/n10_15-21_tn_vn/val.npz',128)\n",
    "batch,batch_labels = next(iter(loader))\n",
    "\n",
    "model.set_use_attn_result(True)\n",
    "_, petersen_cache = model.run_with_cache(petersen_graph.A)\n",
    "_, cycle_cache = model.run_with_cache(cycle_graph.A)\n",
    "_, complete_cache = model.run_with_cache(complete_graph.A)\n",
    "_, empty_cache = model.run_with_cache(empty_graph.A)\n",
    "_, star_cache = model.run_with_cache(star_graph.A)\n",
    "_, random_cache = model.run_with_cache(random_graph.A)\n",
    "_, batch_cache = model.run_with_cache(batch)\n",
    "model.set_use_attn_result(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_planar = 0\n",
    "for g in batch:\n",
    "    graph = Graph(g)\n",
    "    n_planar += nx.is_planar(graph.G)\n",
    "print(f\"{100*n_planar/len(batch):.2f}% of the batch are planar graphs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Plot attention patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_graph.plot_attention(random_cache[\"pattern\",0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: In Head 1.6 vertices of low degree attend stongly to vertex 2. Let's try and work out how each vertex knows whether or not it has low degree. This can easily be read off from the input but we don't know that's what the model is actually doing. \n",
    "\n",
    "My first guess as to how the attention pattern in head 1.6 comes about is this:\n",
    "- Each vertex of low degree has the concept of \"I am a vertex of low degree\" encoded in its residual stream position. \n",
    "- The query matrix for head 1.6 reads this information from the residual stream and produces queries that encode the concept \"I am looking for the special vertex position\" in low degree vertex positions.\n",
    "- The key matrix for head 1.6 produces a key that says \"I am in the special vertex position\" in position 2. I have no idea why, i guess position 2 might contain useful information that the model wants low degree vertices to have?\n",
    "\n",
    "If my guess is true, then any degree information would be passed into head 1.6 via Q-composition from components earlier in the model. Let't take a look at how earlier components contribute to the query and key in head 1.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_index = 6\n",
    "\n",
    "decomposed_qk_input = decompose_qk_input(model,batch_cache)\n",
    "\n",
    "decomposed_q = decompose_q(model, decomposed_qk_input, head_index)\n",
    "decomposed_k = decompose_k(model, decomposed_qk_input, head_index)\n",
    "\n",
    "component_labels = [\"Embed\", \"PosEmbed\"] + [f\"0.{h}\" for h in range(model.cfg.n_heads)]\n",
    "for decomposed_input, name in [(decomposed_q, \"query\"), (decomposed_k, \"key\")]:\n",
    "    px.imshow(\n",
    "        decomposed_input.pow(2).sum(-1).sqrt().mean(0).detach(),\n",
    "        labels={\"x\": \"Position\", \"y\": \"Component\"},\n",
    "        title=f\"Norms of components of {name}\",\n",
    "        y=component_labels,\n",
    "        color_continuous_scale='Blues',\n",
    "        width=1000, height=400\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we believe that the Norms of the components of the query and the key of head 1.6 are correlated with the importance of that component in the function of head1.6, then these plots support my theory that any degree information is passed into head 1.6 via Q-composition from components earlier in the model.\n",
    "Indeed if it was passed via K-composition then we would expect to see components of the key which have high norms across all positions, as low degree vertices can occur at any position.\n",
    "\n",
    "**Further Observations**: \n",
    "- We also see that when creating keys, head 1.6 pretty much only cares about the positional information coming from position 2. This suggests that the concept of \"I want to gather low degree vertices\"&mdash;that is encoded in the position 2 key&mdash;comes entirely from head 1.6 and is not passed on from an earlier component.\n",
    "- The query plot suggests that, out of the previous components, Embed, PosEmbed and head 0.2, are primarily responsible for passing on degree infomation to the vertex positions in head 1.6, with heads 0.1 and 0.3 playing a less important role.\n",
    "\n",
    "These plots are not fully convincing though, as the norm is not obviously a principled indicator of causality from earlier components to later ones. We can get a better idea of which components are causaly important for the function of head 1.6 by taking a single example graph and pairing up individual key and query components and seeing what attention scores they produce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_scores = decompose_attn_scores(decomposed_q, decomposed_k)\n",
    "\n",
    "plot_decomposed_attn_scores(\n",
    "    decomposed_scores=decomposed_scores,\n",
    "    cache=batch_cache,\n",
    "    component_labels=component_labels,\n",
    "    head_idx=6,\n",
    "    batch_sample_idx=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots make me pretty confident that the QK circuit from head 0.2 to PosEmbed via head 1.6 is responsible for moving information from position 2 to low degree vertices. Specifically, head 0.2 Q-composes with head 1.6 and PosEmbed K-composes with head 1.6.\n",
    "\n",
    "While I find this all convincing, one problem with the above plots is that they all rely on activations from a single graph input or a small batch input into the model. It would be great if we could show this relationship between components just by looking at the model weights. We do this by studying the *composition scores* of each pair of components:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Composition Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all QK and OV matrices\n",
    "W_QK = model.W_Q @ model.W_K.transpose(-2, -1)\n",
    "W_OV = model.W_V @ model.W_O\n",
    "\n",
    "mlp_0 = model.blocks[0].mlp\n",
    "\n",
    "# note: adding embed and pos_embed to output spaces may not be very principled (it was my idea and I don't know if anyone else does it)\n",
    "output_space = [\n",
    "    (mlp_0(model.W_E) + model.W_E).unsqueeze(dim=0),\n",
    "    (mlp_0(model.W_pos) + model.W_pos).unsqueeze(dim=0),\n",
    "    *list(mlp_0(W_OV[0]) + W_OV[0])\n",
    "]\n",
    "\n",
    "input_space = {\n",
    "    'Q': W_QK[1],\n",
    "    'K': W_QK[1].transpose(-2,-1),\n",
    "    'V': W_OV[1]\n",
    "}\n",
    "\n",
    "# Define tensors to hold the composition scores\n",
    "composition_scores = {\n",
    "    \"Q\": torch.zeros(model.cfg.n_heads+2, model.cfg.n_heads).to(device),\n",
    "    \"K\": torch.zeros(model.cfg.n_heads+2, model.cfg.n_heads).to(device),\n",
    "    \"V\": torch.zeros(model.cfg.n_heads+2, model.cfg.n_heads).to(device),\n",
    "}\n",
    "\n",
    "for i,out_sp in enumerate(output_space):\n",
    "    for j in range(model.cfg.n_heads):\n",
    "        for comp_type in \"QKV\":\n",
    "            composition_scores[comp_type][i, j] = get_comp_score(out_sp, input_space[comp_type][j])\n",
    "\n",
    "# baseline\n",
    "n_samples = 300\n",
    "comp_scores_baseline = np.zeros(n_samples)\n",
    "for i in tqdm(range(n_samples)):\n",
    "    comp_scores_baseline[i] = generate_single_random_comp_score(model)\n",
    "\n",
    "# px.histogram(\n",
    "#     comp_scores_baseline,\n",
    "#     nbins=50,\n",
    "#     width=800,\n",
    "#     labels={\"x\": \"Composition score\"},\n",
    "#     title=\"Random composition scores\"\n",
    "# )\n",
    "\n",
    "for comp_type in \"QKV\":\n",
    "    plot_comp_scores(\n",
    "        model,\n",
    "        composition_scores[comp_type], \n",
    "        title=f\"{comp_type} Composition Scores\",\n",
    "        component_labels=component_labels,\n",
    "        baseline=comp_scores_baseline.mean()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This strongly supports my theory: it would be a pretty big coincidence if the output space of head 0.2 happend to be the only layer 0 head to have a strong overlap with the query input space of head 1.6 and head 0.2 wasn't integral to head 1.6's functionality. Similarly, we see that the output space of PosEmbed has a strong overlap with the key input space of head 1.6.\n",
    "\n",
    "If you still aren't convinced then let's take a \"corrupted\" graph with (in some sense) no low degree vertices as model input and then patch in the cached head 0.2 activations for a \"clean\" graph with some low degree vertices and see to what extent we can reproduce the \"clean\" behaviour of head 1.6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Activation Patching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads_to_patch = [[2],[1,3],[1,2,3],[0],[4],[5],[6],[7],[0,4,5,6,7]]\n",
    "\n",
    "px.imshow(random_cache[\"pattern\",1][0,6],color_continuous_scale='Blues',title=\"Clean Pattern\").show()\n",
    "px.imshow(petersen_cache[\"pattern\",1][0,6],color_continuous_scale='Blues',title=\"Corrupted Pattern\",zmax=1).show()\n",
    "\n",
    "model.reset_hooks()\n",
    "patched_cache = model.add_caching_hooks('blocks.1.attn.hook_pattern')\n",
    "\n",
    "for heads in heads_to_patch:\n",
    "    run_with_patched_heads(model,petersen_graph.A,random_cache,heads)\n",
    "\n",
    "    head_string = ' '.join(f'0.{head}' for head in heads)\n",
    "\n",
    "    px.imshow(\n",
    "        patched_cache['blocks.1.attn.hook_pattern'][0,6],\n",
    "        color_continuous_scale='Blues',\n",
    "        title=f\"Pattern with {head_string} patched\",\n",
    "        zmax=1\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_metric( \n",
    "    patched_cache: ActivationCache,\n",
    "    clean_cache: ActivationCache,\n",
    ") -> Float[Tensor, \"\"]:\n",
    "    patched_pattern = patched_cache['blocks.1.attn.hook_pattern']\n",
    "    clean_pattern = clean_cache['blocks.1.attn.hook_pattern']\n",
    "    return torch.norm(patched_pattern[0,6]-clean_pattern[0,6])\n",
    "\n",
    "rank_heads_by_patching_metric(model,petersen_graph.A,random_cache,pattern_metric,'blocks.1.attn.hook_pattern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's follow this trail back through the model by looking more closely at head 0.2.\n",
    " \n",
    "**Observation**: Vertices of high degree attend more to vertices 3 and 6, whereas vertices of low degree seem to attend evenly to all vertices.\n",
    "Although this pattern has far more evenly distributed&mdash;and therefore smaller&mdash;probabilities, it's functionality seems pretty similar to head 1.6, except with \"low degree\" swapped with \"high degree\" and position 2 swapped with positions 3 and 6.\n",
    "\n",
    "Let's test this theory using similar techniques. As before, we decompose the input to the head into components. Because this is the layer 0 we only have two input components: Embed and PosEmbed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_qk_input_layer_0 = decompose_qk_input(model, batch_cache, layer=0)\n",
    "decomposed_q_layer_0 = decompose_q(model,decomposed_qk_input_layer_0,head_index=2,layer=0)\n",
    "decomposed_k_layer_0 = decompose_k(model,decomposed_qk_input_layer_0,head_index=2,layer=0)\n",
    "\n",
    "component_labels_layer_0 = [\"Embed\", \"PosEmbed\"]\n",
    "for decomposed_input, name in [(decomposed_q_layer_0, \"query\"), (decomposed_k_layer_0, \"key\")]:\n",
    "    px.imshow(\n",
    "        decomposed_input.pow(2).sum(-1).sqrt().mean(0).detach(),\n",
    "        labels={\"x\": \"Position\", \"y\": \"Component\"},\n",
    "        title=f\"Norms of components of {name}\",\n",
    "        y=component_labels_layer_0,\n",
    "        color_continuous_scale='Blues',\n",
    "        width=1000, height=400\n",
    "    ).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots are very similar to the ones we got for head 1.6, supporting our theory. Indeed, head 0.2 seems like it is only interested in moving information from positions 3 and 6 to vertices based purely on their embedding (and not their position).\n",
    "To be more certain we will plot the decomposed attention scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_scores_layer_0 = decompose_attn_scores(decomposed_q_layer_0, decomposed_k_layer_0)\n",
    "\n",
    "plot_decomposed_attn_scores(\n",
    "    decomposed_scores=decomposed_scores_layer_0,\n",
    "    cache=batch_cache,\n",
    "    component_labels=component_labels_layer_0,\n",
    "    layer=0,\n",
    "    head_idx=2,\n",
    "    batch_sample_idx=100,\n",
    "    zmax=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now my questions are: \n",
    "- What information is being moved from postions 3 and 6 to the vertices of high degree?\n",
    "- How exactly does `W_Q[0,2]` give the query vectors a concept of degree based on `input @ W_E`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **OV circuit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OV_circuit(model,layer,head):\n",
    "    W_O = model.W_O[layer, head]\n",
    "    W_V = model.W_V[layer, head]\n",
    "    W_E = model.W_E\n",
    "    W_U = model.W_U\n",
    "\n",
    "    OV_circuit = FactoredMatrix(W_V, W_O)\n",
    "    full_OV_circuit = W_E @ OV_circuit @ W_U\n",
    "    return full_OV_circuit, OV_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmax = 0.4\n",
    "\n",
    "layers = list(range(model.cfg.n_layers))\n",
    "heads = list(range(model.cfg.n_heads))\n",
    "fig = make_subplots(\n",
    "    rows=2, \n",
    "    row_titles=[str(i) for i in layers],\n",
    "    cols=8,\n",
    "    column_titles=[str(i) for i in heads]\n",
    ")\n",
    "\n",
    "for layer in layers:\n",
    "    for head_index in heads:\n",
    "        full_OV_circuit, OV_circuit = get_OV_circuit(model,layer,head_index)\n",
    "        heatmap = go.Heatmap(z=OV_circuit.AB.detach(),zmin=-zmax,zmax=zmax,colorscale='RdBu')\n",
    "        fig.add_trace(heatmap, row=layer+1, col=head_index+1)\n",
    "        fig.update_yaxes(autorange='reversed')\n",
    "\n",
    "# Update the layout for better visualization\n",
    "fig.update_layout(height=600, width=2000, showlegend=False)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    get_OV_circuit(model,0,2)[1].AB.detach(),\n",
    "    color_continuous_scale=\"RdBu\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualise neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acts(model,cache):\n",
    "    \"\"\"\n",
    "    Plots mean neuron activations for all mlp layers in cache.\n",
    "    \"\"\" \n",
    "    assert len(cache['embed'].shape) > 2, \"No batch dimension found.\"\n",
    "    for i in range(model.cfg.n_layers):\n",
    "        px.imshow(\n",
    "            cache[\"mlp_post\",i].mean(0), # mean over batch dimension\n",
    "            y=[f\"0.{h}\" for h in range(model.cfg.n_vertices)],\n",
    "            labels={\"x\": \"Neurons\", \"y\": \"Vertices\"},\n",
    "            title=f\"Layer {i} Neuron Activations\",\n",
    "            color_continuous_scale=\"Blues\"\n",
    "        ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acts(model,batch_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Correlation between neuron activation and vertex degree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_act_correlation(\n",
    "    input: Float[Tensor,\"batch n_vertices n_vertices\"],\n",
    "    acts: Float[Tensor,\"batch n_vertices d_mlp\"]\n",
    "):\n",
    "    degrees = input.sum(dim=-1) # batch n_vertices\n",
    "    degrees_flattened = einops.rearrange(\n",
    "        degrees,\n",
    "        \"batch n_vertices -> 1 (batch n_vertices)\"\n",
    "    )\n",
    "\n",
    "    acts_flattened = einops.rearrange(\n",
    "        acts,\n",
    "        \"batch n_vertices d_mlp-> d_mlp (batch n_vertices)\"\n",
    "    )\n",
    "\n",
    "    degree_acts_stack = torch.cat([degrees_flattened,acts_flattened]) # (batch n_vertices) d_mlp+1\n",
    "    print(degree_acts_stack.shape)\n",
    "    correlations = torch.corrcoef(degree_acts_stack)[0,1:] # d_mlp\n",
    "\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_dataloader('adj','data/n10_15-21_tn_vn/val.npz',128)\n",
    "input, _ = next(iter(loader))\n",
    "_, cache = model.run_with_cache(input)\n",
    "degree_act_correlations = get_degree_act_correlation(input, cache['mlp_post',1])\n",
    "px.line(\n",
    "    y=degree_act_correlations.detach(),\n",
    "    labels={\"x\": \"Neuron\", \"y\": \"Correlation with degree\"},\n",
    "    title=f\"Correlation between neuron activation and degree\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logit attribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_results, component_captions = batch_cache.get_full_resid_decomposition(return_labels=True, expand_neurons=False)\n",
    "layer_results = torch.stack([v for k,v in batch_cache.items() if 'out' in k])\n",
    "layer_captions = [k for k in cache if 'out' in k]\n",
    "\n",
    "logit_diff_directions = get_logit_diff_directions(model,batch_labels)\n",
    "\n",
    "component_logit_attribution = get_logit_attribution(component_results,logit_diff_directions)\n",
    "layer_logit_attribution = get_logit_attribution(layer_results,logit_diff_directions)\n",
    "\n",
    "plot_logit_attribution(component_logit_attribution,component_captions)\n",
    "plot_logit_attribution(layer_logit_attribution,layer_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate 1_mlp_out further**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_results = einops.rearrange(\n",
    "    batch_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "neuron_logit_attribution = get_logit_attribution(neuron_results,logit_diff_directions)\n",
    "\n",
    "plot_logit_attribution(neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Make datasets of specific examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = {\n",
    "    'n': model.cfg.n_vertices,\n",
    "    'size': 1099,\n",
    "    'start': 15,\n",
    "    'end': 22\n",
    "}\n",
    "\n",
    "planar_graphs = generate_planar(**dataset_kwargs)\n",
    "\n",
    "non_planar_graphs = generate_planar(**dataset_kwargs, non_planar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_graphs, correct_labels = generate_misclass(\n",
    "    model=model,\n",
    "    start=15,\n",
    "    end=17,\n",
    "    size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adj in misclassified_graphs:\n",
    "    g = Graph(adj)\n",
    "    is_planar,cert = nx.check_planarity(g.G, counterexample=True)\n",
    "    print(is_planar)\n",
    "    Graph(cert).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study average activations across sets of specific examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_use_attn_result(True)\n",
    "_, planar_cache = model.run_with_cache(planar_graphs)\n",
    "_, non_planar_cache = model.run_with_cache(non_planar_graphs)\n",
    "_, misclassified_cache = model.run_with_cache(misclassified_graphs)\n",
    "model.set_use_attn_result(False)\n",
    "\n",
    "plot_acts(model,planar_cache)\n",
    "plot_acts(model,non_planar_cache)\n",
    "plot_acts(model,misclassified_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logit attributions across sets of specific examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planar_neuron_results = einops.rearrange(\n",
    "    planar_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "non_planar_neuron_results = einops.rearrange(\n",
    "    non_planar_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "misclassified_neuron_results = einops.rearrange(\n",
    "    misclassified_cache.get_neuron_results(layer=1),\n",
    "    \"batch n_vertices n_neurons d_model -> n_neurons batch n_vertices d_model\"\n",
    ")\n",
    "\n",
    "planar_logit_diff_directions = get_logit_diff_directions(model,torch.ones(dataset_kwargs['size'],dtype=torch.int64))\n",
    "non_planar_logit_diff_directions = get_logit_diff_directions(model,torch.zeros(dataset_kwargs['size'],dtype=torch.int64))\n",
    "misclassified_logit_diff_directions = get_logit_diff_directions(model,torch.zeros(len(misclassified_graphs),dtype=torch.int64))\n",
    "\n",
    "planar_neuron_logit_attribution = get_logit_attribution(planar_neuron_results,planar_logit_diff_directions)\n",
    "non_planar_neuron_logit_attribution = get_logit_attribution(non_planar_neuron_results,non_planar_logit_diff_directions)\n",
    "misclassified_neuron_logit_attribution = get_logit_attribution(misclassified_neuron_results,misclassified_logit_diff_directions)\n",
    "\n",
    "plot_logit_attribution(planar_neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])\n",
    "plot_logit_attribution(non_planar_neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])\n",
    "plot_logit_attribution(misclassified_neuron_logit_attribution,[str(i) for i in range(model.cfg.d_mlp)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aisf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
